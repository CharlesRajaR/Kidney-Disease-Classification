{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cbc82df",
   "metadata": {},
   "source": [
    "# Transfer learning & fine-tuning\n",
    "\n",
    "**Author:** Charles Raja R <br>\n",
    "**Description:** Complete guide to transfer learning & fine-tuning in Keras.<br>\n",
    "**Link:** https://colab.research.google.com/github/keras-team/keras-io/blob/master/guides/ipynb/transfer_learning.ipynb#scrollTo=rBENYxlIsMCm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e049142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5874a804",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Transfer learning** consists of taking features learned on one problem, and\n",
    "leveraging them on a new, similar problem. For instance, features from a model that has\n",
    "learned to identify racoons may be useful to kick-start a model meant to identify tanukis.\n",
    "\n",
    "Transfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n",
    "\n",
    "1. Take layers from a previously trained model.\n",
    "2. Freeze them, so as to avoid destroying any of the information they contain during\n",
    " future training rounds.\n",
    "3. Add some new, trainable layers on top of the frozen layers. They will learn to turn\n",
    " the old features into predictions on a  new dataset.\n",
    "4. Train the new layers on your dataset.\n",
    "\n",
    "A last, optional step, is **fine-tuning**, which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate. This can potentially achieve meaningful improvements, by incrementally adapting the pretrained features to the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9452b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 11:47:50.482557: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-10 11:47:50.530683: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-10 11:47:52.655881: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/workspaces/Kidney-Disease-Classification/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "2026-01-10 11:47:54.763879: W external/local_xla/xla/tsl/platform/cloud/google_auth_provider.cc:185] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Could not resolve hostname', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract_reasoning', 'accentdb', 'aeslc', 'aflw2k3d', 'ag_news_subset']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# List some available datasets to confirm connectivity\n",
    "print(tfds.list_builders()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcef97a",
   "metadata": {},
   "source": [
    "## Freezing layers: understanding the `trainable` attribute\n",
    "\n",
    "Layers & models have three weight attributes:\n",
    "\n",
    "- `weights` is the list of all weights variables of the layer.\n",
    "- `trainable_weights` is the list of those that are meant to be updated (via gradient\n",
    " descent) to minimize the loss during training.\n",
    "- `non_trainable_weights` is the list of those that aren't meant to be trained.\n",
    " Typically they are updated by the model during the forward pass.\n",
    "\n",
    "**Example: the `Dense` layer has 2 trainable weights (kernel & bias)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18403b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dense name=dense, built=False>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d403fb",
   "metadata": {},
   "source": [
    "In general, all weights are trainable weights. The only built-in layer that has\n",
    "non-trainable weights is the `BatchNormalization` layer. It uses non-trainable weights\n",
    " to keep track of the mean and variance of its inputs during training.\n",
    "To learn how to use non-trainable weights in your own custom layers, see the\n",
    "[guide to writing new layers from scratch](/guides/making_new_layers_and_models_via_subclassing/).\n",
    "\n",
    "**Example: the `BatchNormalization` layer has 2 trainable weights and 2 non-trainable\n",
    " weights**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7837d038",
   "metadata": {},
   "source": [
    "**What is Batch Normalization?**<br>\n",
    "Batch Normalization accelerates training and improves stability by normalizing the inputs of each layer. It scales and shifts activations to maintain a consistent mean and variance, reducing sensitivity to initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8296858",
   "metadata": {},
   "source": [
    "**What is convolutional layers?**\n",
    "A convolutional layer uses small filters (kernels) to scan images, extracting key features like edges or textures. It preserves spatial relationships while reducing data complexity, forming the foundation of CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4538b067",
   "metadata": {},
   "source": [
    "**What is activation Layer?**\n",
    "It applies a mathematical function (like ReLU) to the output, introducing non-linearity. This allows the model to learn complex patterns instead of just simple linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cc84d4",
   "metadata": {},
   "source": [
    "**What is MaxPooling2D layer?**\n",
    "This layer reduces the spatial dimensions (height/width) of images by keeping only the maximum value in a window. It shrinks data size while retaining the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8c1fd",
   "metadata": {},
   "source": [
    "**What is Flatten Layer?**\n",
    "It converts a multi-dimensional feature map (like a 2D image) into a single long 1D vector. This \"unrolling\" prepares the data for the final classification layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbd44e",
   "metadata": {},
   "source": [
    "**What is Dense Layer?**\n",
    "A fully connected layer where every input neuron connects to every output neuron. It performs the final logic, combining all extracted features to predict the specific image category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254cf70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Kidney-Disease-Classification/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Example code using batch normalization\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential([\n",
    "    # 1. Convolutional Layer\n",
    "    layers.Conv2D(32, (3, 3), input_shape=(224, 224, 3)),\n",
    "    \n",
    "    # 2. Batch Normalization (Placed BEFORE the activation)\n",
    "    layers.BatchNormalization(),\n",
    "    # why this layer? \n",
    "    # Without it: If the pixel values in the input image are very different,\n",
    "    #the model might struggle to learn at a steady pace. \n",
    "\n",
    "    # With it: It \"recenters\" the data. This allows you to use a higher\n",
    "    #  learning rate, making your training much faster and less likely to\n",
    "    #  crash.\n",
    "\n",
    "    \n",
    "    # 3. Activation\n",
    "    layers.Activation('relu'),\n",
    "    \n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebb47adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 2\n",
      "trainable_weights: 2\n",
      "non_trainable_weights: 0\n"
     ]
    }
   ],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer.build((None, 4))  # Create the weights\n",
    "layer.trainable = True  # Freeze the layer\n",
    "\n",
    "print(\"weights:\", len(layer.weights))\n",
    "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a4f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: 2\n",
      "trainable_weights: 0\n",
      "non_trainable_weights: 2\n"
     ]
    }
   ],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer.build((None, 4))  # Create the weights\n",
    "layer.trainable = False  # Freeze the layer\n",
    "\n",
    "print(\"weights:\", len(layer.weights))\n",
    "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160e81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape=(3,)\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dee177e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51906519, 0.81934024, 0.19999991],\n",
       "       [0.72525594, 0.46474565, 0.52695146]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49f90208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.023283  , 0.1121046 , 0.42043985],\n",
       "        [0.80346184, 0.81025372, 0.73415878]]),\n",
       " array([[0.11021325, 0.52658641, 0.10283493],\n",
       "        [0.0625319 , 0.71689214, 0.69571295]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((2, 3)), np.random.random((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea2b11d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 3), dtype=float32, sparse=False, ragged=False, name=keras_tensor_14>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.Input(shape=(3, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c68ec",
   "metadata": {},
   "source": [
    "**what is relu activation function?**<br>\n",
    "ReLU (Rectified Linear Unit) An activation function that outputs the input directly if positive, otherwise zero. It introduces non-linearity, helping models learn complex patterns while preventing training slowdowns compared to older functions.\n",
    "<br>\n",
    "<br>\n",
    "**What is adam optimizer?**<br>\n",
    "Adam An advanced optimizer that automatically adjusts the learning rate for each parameter. It combines the benefits of `momentum and adaptive gradients`, making it fast, robust, and very popular.\n",
    "<br>\n",
    "<br>\n",
    "**what is weights?**<br>\n",
    "The learnable parameters inside neurons that determine the \"strength\" of a connection. During training, the model adjusts these numbers to minimize errors and improve prediction accuracy.\n",
    "<br>\n",
    "<br>\n",
    "**what is optimizer?**<br>\n",
    "The algorithm that updates the model's weights based on the loss function. It acts like a guide, telling the model how to change its parameters to reach the best performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7023001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999ms/step - loss: 0.1403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7add815415b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a model with 2 layers\n",
    "layer1 = keras.layers.Dense(units=3, activation=\"relu\")\n",
    "# what is units? \n",
    "# Units represent the number of neurons in the layer. \n",
    "# Each unit acts as a single learning node that detects a specific feature,\n",
    "# outputting 3 distinct values for the next layer.\n",
    "layer2 = keras.layers.Dense(units=3, activation=\"sigmoid\")\n",
    "model = keras.Sequential([keras.Input(shape=(3, )), layer1, layer2])\n",
    "\n",
    "layer1.trainable = False\n",
    "initial_layer1_weights_values = layer1.get_weights()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c125dedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initial_layer1_weights_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1f160ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.06940031,  0.9313228 ,  0.10630417],\n",
       "        [ 0.18633103,  0.28914762,  0.8375237 ],\n",
       "        [ 0.9452481 , -0.12755728, -0.13433862]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_layer1_weights_values[0], initial_layer1_weights_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ef188d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer1_weights_values = layer1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1795f5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.06940031,  0.9313228 ,  0.10630417],\n",
       "        [ 0.18633103,  0.28914762,  0.8375237 ],\n",
       "        [ 0.9452481 , -0.12755728, -0.13433862]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_layer1_weights_values[0], final_layer1_weights_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4300613",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer1_weights_values = layer1.get_weights()\n",
    "# This code Raises an AssertionError if two objects are not equal up to desired tolerance.\n",
    "np.testing.assert_allclose(\n",
    "    initial_layer1_weights_values[0], final_layer1_weights_values[0]\n",
    ")\n",
    "np.testing.assert_allclose(\n",
    "    initial_layer1_weights_values[1], final_layer1_weights_values[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "336ef6b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=0\n\nMismatched elements: 1 / 1 (100%)\nMax absolute difference among violations: 1\nMax relative difference among violations: 1.\n ACTUAL: array(0)\n DESIRED: array(1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m.\u001b[49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/Kidney-Disease-Classification/.venv/lib/python3.12/site-packages/numpy/testing/_private/utils.py:983\u001b[39m, in \u001b[36massert_array_compare\u001b[39m\u001b[34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict, names)\u001b[39m\n\u001b[32m    978\u001b[39m         err_msg += \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m + \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.join(remarks)\n\u001b[32m    979\u001b[39m         msg = build_err_msg([ox, oy], err_msg,\n\u001b[32m    980\u001b[39m                             verbose=verbose, header=header,\n\u001b[32m    981\u001b[39m                             names=names,\n\u001b[32m    982\u001b[39m                             precision=precision)\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m    985\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtraceback\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: \nNot equal to tolerance rtol=1e-07, atol=0\n\nMismatched elements: 1 / 1 (100%)\nMax absolute difference among violations: 1\nMax relative difference among violations: 1.\n ACTUAL: array(0)\n DESIRED: array(1)"
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(\n",
    "    0, 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fa9a5c",
   "metadata": {},
   "source": [
    "## Recursive setting of the `trainable` attribute\n",
    "\n",
    "If you set `trainable = False` on a model or on any layer that has sublayers,\n",
    "all children layers become non-trainable as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
